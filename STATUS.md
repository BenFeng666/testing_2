# Project Status Summary

**Date**: 2025-10-14  
**Location**: `/users/7/li003385/workspace/Ai4drug/Sai_nemo_AI4drug`

---

## âœ… Completed

### 1. Project Setup
- âœ… Cloned repository
- âœ… Created clean directory structure
- âœ… Data normalized to [1-10] integers
- âœ… Split: 200 training + 1000 test samples

### 2. Qwen2-7B Model  
- âœ… Trained with 8-bit quantization on H100
- âœ… Training time: 4.5 minutes
- âœ… Evaluated on 1000 test samples
- âœ… **Accuracy (Â±1)**: **53.5%** 
- âœ… Exact match: 23.9%
- âœ… Model saved: `models/qwen_7b/checkpoints/`

### 3. File Structure Reorganization
- âœ… Separated 7B and 30B directories
- âœ… Unified documentation (README_MODELS.md)
- âœ… Updated evaluation standard (Â±1 counts as correct)

---

## ğŸ”„ In Progress

### Qwen3-30B Model
- **Job ID**: 42158227
- **GPU**: 2x A100 (agb02)
- **Status**: Running (21+ minutes)
- **Issue**: Training stuck at 0/21 steps (possible kernel version issue)

**Note**: System kernel 4.18.0 is below recommended 5.5.0, which may cause process hang.

---

## ğŸ“ Final Structure

```
models/
â”œâ”€â”€ qwen_7b/              # Qwen2-7B âœ… DONE
â”‚   â”œâ”€â”€ scripts/          # train_7b.py, evaluate_7b.py, job scripts
â”‚   â”œâ”€â”€ checkpoints/      # qwen_lora_finetuned/ (78MB)
â”‚   â””â”€â”€ output/           # evaluation_results_7b.json
â”‚
â””â”€â”€ qwen_30b/             # Qwen3-30B ğŸ”„ TRAINING
    â”œâ”€â”€ scripts/          # train_30b.py, evaluate_30b.py, job scripts
    â”œâ”€â”€ checkpoints/      # (will be created after training)
    â””â”€â”€ output/           # (will be created after evaluation)

data/                     # Shared data
â”œâ”€â”€ train_data.jsonl (200)
â””â”€â”€ test_data.jsonl (1000)
```

---

## ğŸ“Š Results with New Evaluation Standard

**Evaluation Criteria**: Predictions within Â±1 error are considered correct.

### Qwen2-7B Results:
- **Accuracy (Â±1 allowed)**: **53.5%** âœ… Main metric
- **Exact match rate**: 23.9%
- **MAE**: 1.59
- **RMSE**: 2.04

### Qwen3-30B Results:
- Pending training completion

---

## ğŸ¯ Next Options

### Option 1: Wait for 30B training
```bash
# Monitor (training may take hours if stuck)
tail -f logs/train_30b_42158227.err | grep "%"
```

### Option 2: Cancel and retry with different configuration
```bash
scancel 42158227

# Try with single GPU or different partition
# Edit: models/qwen_30b/scripts/train_job_30b.sh
```

### Option 3: Use 7B results
- 7B model is working and provides 53.5% accuracy
- Results available in `models/qwen_7b/output/`

---

## ğŸ“š Documentation

**Main Guide**: `README_MODELS.md`  
**Status**: This file

---

## ğŸ”— Key Commands

```bash
# Check jobs
squeue -u li003385

# View 7B results
cat models/qwen_7b/output/evaluation_results_7b.json

# Monitor 30B
tail -f logs/train_30b_*.err

# Cancel 30B if needed
scancel 42158227
```

---

**Status**: 7B âœ… Complete | 30B ğŸ”„ Training (may be stuck)

